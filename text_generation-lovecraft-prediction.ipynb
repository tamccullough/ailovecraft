{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 unique characters\n"
     ]
    }
   ],
   "source": [
    "path_to_file = 'lovecraft.txt'# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) # Length of the vocabulary in chars\n",
    "embedding_dim = 256 # The embedding dimension\n",
    "rnn_units = 1024 # Number of RNN units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = 'model/'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zk2WJ2-XjkGz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/ckpt_20'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f878ff05610> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f878ff05690>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent_v2.GRU object at 0x7f8793ae7910> and <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f878ff05610>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f87e8529050> and <tensorflow.python.keras.layers.recurrent_v2.GRU object at 0x7f8793ae7910>).\n"
     ]
    }
   ],
   "source": [
    "lovecraft_predict = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "lovecraft_predict.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "lovecraft_predict.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "71xa6jnYVrAN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            33024     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 129)            132225    \n",
      "=================================================================\n",
      "Total params: 4,103,553\n",
      "Trainable params: 4,103,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lovecraft_predict.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string,temp):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = temp\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        send_text = ''.join(text_generated)\n",
    "        #send_text = send_text.split('\\n')[0]\n",
    "\n",
    "    #return (start_string + ''.join(text_generated))\n",
    "    return send_text#(start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“There were two or through, pured with disappointment to work; then and the interment in the strang, Lady and decked together a-tempeth Capt. \n",
      "James, I will nor beyond how he had oddly snapped it. \n",
      "And I knew that the world had happened to lip. \n",
      "It ran as faded past bearing the time sooth thouse no longer heers that dack—his body jeck, who was the death of the Most Rice and Sydney and his intangible Juanna for Zumbardn for them. \n",
      "I have said that some supernatural altering had been so far off. \n",
      "Three coffin-grown civilisations sent from the earth and forced the loveliness below, and laden were no less frequently enough to hurry across the dissection built in both difficulty; and in bringing Barzai the voices of Yoth had thrown them with the air and will system fe that this side of the house he had made signs of apprehension. \n",
      "That people it was darker and pool which, though his buildings, from the ultimately to be revoked the facts. \n",
      "As we replied, it was thou always, unconscious cond\n"
     ]
    }
   ],
   "source": [
    "user_input = 'She crept slowly through the ferns, careful to be silent in the night.'#input('')\n",
    "print(generate_text(lovecraft_predict, start_string=user_input+u'\\n',temp=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“He was rich and curved steeples with the dead world of the most ancient amounts of the ancient world, I studied the thin hope that the bargain was a permanent form of fright and disconcerting him, and he drawn in a former distance seeming to be done about the deserted city of his shini, vocal orial processions converse some pathological traveller’s ect. \n",
      "There were more terrible odours, for they were not the tripods to the opposite fish-priests. \n",
      "Mr. Bredence of this fought I could not be surprised to hold forth the noise was a mafter and leand the other twilight! \n",
      "Even events I regretted—handed down the sky like the damnable Elmed Alber 1928, and that trees with evil shadows resounted to find the fullest expanse of the edifices so small and muffled seas. \n",
      "One morning crystal was still lorded in his chaot and its mate. \n",
      "“Don’t see it, everyone seemed to be quick.” And in the morning I was considerable exterior, and helped him he seemed at times in the tomb, and a fantastic not very s\n"
     ]
    }
   ],
   "source": [
    "user_input = 'She crept slowly through the ferns, careful to be silent in the night.'#input('')\n",
    "print(generate_text(lovecraft_predict, start_string=user_input+u'\\n',temp=0.87))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "I am a desire to explain that the thing was made up the strange things of men and descend from the stars and glimmered or the last of the strange days of his sister and louder. \n",
      "The strange markings were still there, and a sound will not do to breathe the desert and the stones with the deserted streets and colonial type, while the people had so far as I could not be sure. \n",
      "It was the first time since the passage was the first time since the poor devil were all the strange days with the great black stone steps to the door and the strange myths of the strange things that had been a man of great silver key which had been a deep bank wall of the deserted city of man to see the strange things about the deserted horizon as a madman’s raving at the same time been the sinister places I beheld the common cities of the hills, and on the other hand was a deep and sensible and unhallowed cliff, and the strange things were the land of the deserted mansion which the doctor was discovered. \n",
      "The con\n"
     ]
    }
   ],
   "source": [
    "user_input = 'She crept slowly through the ferns, careful to be silent in the night.'#input('')\n",
    "print(generate_text(lovecraft_predict, start_string=user_input+u'',temp=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“The party was something wholly clear to me with the strange things and the strange days of many strange designs and of the strange things which have driven me to the southwest and the strange days of my father’s farm the sea and the stars while he saw the substance of the strange beings who had been a strange and absorb which formed the strange cities and into the stars and the strange days of my father’s farm the sea and the stars while he saw the substance of the strange beings who had been a strange and absorbing door and send him about the deserted mansion and shapeless and fear-broken panes of the sea. \n",
      "There was a sense of familiarity with the death of his house and grown up a prodigious vaulted chamber and shape and strove to recall the strange characters who did not seem to be a devil and despair that the past was the first time since the poor devil were freely present. \n",
      "Some of the first hideous masonry was closed the door and the strange days of my father, who had been a st\n"
     ]
    }
   ],
   "source": [
    "user_input = 'She crept slowly through the ferns, careful to be silent in the night.'#input('')\n",
    "print(generate_text(lovecraft_predict, start_string=user_input+u'\\n',temp=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lovecraft_predict.save('model/lovecraft_predict.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "reconstructed_model = tf.keras.models.load_model('model/lovecraft_predict.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ght about 500 spades who prese a more induced blood in this beautiful host avoid. \n",
      "Or cryh with that lurked delight—the abysses; and disfurbed needlessly through the dreaded door of strange dreams. \n",
      "Mr. Phillips, through the houses we had hoped for the day before “15G of The Landwas adverse yet even far ahead. \n",
      "After an human person who found me utterly not at the first to cut through the sight, I tried to feel that some supposed to follow what you have done it would disable o’clock. \n",
      "There were curious greeter because of their need, was no sound, the dawn was over William, the ebid a lamparies of change. \n",
      "Only what I had shewn gnable just where, if you’re telephonesen and the wall were throng forms shewed for blood. \n",
      "I shall never cease, but was gradually on their tentacles of whose sea-green shobs overheap faor’s stone’s decorative capt were missing. \n",
      "The man at Exer) plunge his llearie, half-wholesome blasphemy upward. \n",
      "Could the heavy mist that strange bothered, with their tentacle\n"
     ]
    }
   ],
   "source": [
    "user_input = 'She crept slowly through the ferns, careful to be silent in the night.'#input('')\n",
    "print(generate_text(reconstructed_model, start_string=user_input+u'\\n',temp=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
